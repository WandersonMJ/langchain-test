# MELHORIAS - SISTEMA DE AGENDAMENTO IA WHATSAPP B2B

## PROBLEMA IDENTIFICADO
- **Nome técnico:** "Conversational Slot Filling com Validação de Constraints Complexas"
- **Desafio:** Coletar informações em ordem flexível ENQUANTO valida regras de negócio interdependentes
- **Constraints:** profissional ↔ serviço ↔ horário ↔ agenda (todos interligados)

## ARQUITETURA PROPOSTA

```
User → LLM extrai intenção/slots → 
Controlador Node.js valida regras → 
Retorna opções válidas → 
LLM responde naturalmente
```

### Fluxo:
1. User: "Quero massagem com a Dra Ana"
2. LLM extrai: {serviço: "massagem", profissional: "Ana"}
3. Node.js valida: Ana faz massagem? Horários disponíveis?
4. LLM responde: "Ótimo! Dra Ana tem massagem. Prefere manhã ou tarde?"

## TIPOS DE INTERAÇÃO

### INFORMATIVAS (não mudam estado)
- "O que é drenagem linfática?"
- "A Dra Ana atende sábado?"
- LLM responde direto com dados disponíveis

### TRANSACIONAIS (avançam agendamento)
- "Quero agendar massagem"
- "Prefiro com a Dra Ana"
- Controlador valida + atualiza slots coletados

### CLASSIFICAÇÃO DE INTENÇÃO
- `QUERY` (informativa) → responde e volta
- `BOOK_SLOT` (transacional) → valida e avança
- `CHANGE_MIND` → limpa slots e recomeça

## FUNCTION CALLING (TOOLS)

### Tools necessárias:
- `buscar_servico(nome)` 
- `buscar_profissional(nome)`
- `verificar_agenda(profissional_id, data)`
- `listar_horarios_disponiveis(profissional_id, servico_id, data)`

### Como funciona:
- User: "A Dra Ana atende sábado?"
- LLM escolhe tools: buscar_profissional("Ana") → verificar_agenda(ana_id, "sábado")
- Você implementa as funções, LLM decide qual usar

## ESTADO INTERMEDIÁRIO

Manter contexto durante conversa:
```json
{
  "servico": "massagem",
  "profissional": null,
  "data": null,
  "slots_coletados": ["servico"]
}
```

Mesmo com perguntas no meio, mantém progresso.

## MODELOS DE IA

### Problema atual:
- GPT-4o-mini: fraco em function calling complexo
- Economiza centavos, perde reais em bugs

### Solução híbrida:
- **Conversas simples/FAQ:** modelo barato
- **Validações críticas:** modelo melhor

### Recomendação para teste:
- **Claude 3 Haiku:** melhor function calling, preço similar ao gpt-4o-mini
- **Claude 3.5 Haiku:** meio-termo
- Verificar https://docs.anthropic.com/en/docs/about-claude/models

### Custo estimado:
- 1 agendamento = 10-20 msgs = $0.01-0.05
- 1000 agendamentos/mês = $10-50
- Cliente B2B paga por qualidade

## PRÓXIMOS PASSOS

1. Isolar módulo de IA atual
2. Criar módulo Anthropic paralelo
3. Testar Claude 3 Haiku vs GPT-4o-mini
4. Comparar taxa de erro em function calling
5. Implementar controlador Node.js para validação de regras
6. Separar ações informativas vs transacionais

## OBSERVAÇÕES IMPORTANTES

- LLM = interface conversacional (não gerente do processo)
- Node.js = gerente de regras de negócio
- Tools bem descritas = LLM escolhe certo
- Anthropic: $5 grátis para testes iniciais